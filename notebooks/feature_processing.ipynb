{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86796a1",
   "metadata": {},
   "source": [
    "# NFL Player Position Prediction - Feature Engineering\n",
    "\n",
    "This notebook processes the NFL tracking data into three normalized feature sets:\n",
    "1. Player-level features (per player, per frame)\n",
    "2. Team-frame features (per team, per frame)\n",
    "3. Play-level features (per play summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 18:00:25,834 - INFO - Project root configured: e:\\OneDrive\\Documents\\Courses\\Artificial Intelligence\\Project\\UF_CAP4261_F25_TEAM9\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Setup project path\n",
    "proj = Path.cwd()\n",
    "if (proj / \"src\").exists():\n",
    "    root = proj\n",
    "elif (proj.parent / \"src\").exists():\n",
    "    root = proj.parent\n",
    "else:\n",
    "    root = next(p for p in [proj, *proj.parents] if (p / \"src\").exists())\n",
    "\n",
    "# Set up python path\n",
    "os.chdir(root)\n",
    "if str(root) not in sys.path:\n",
    "    sys.path.insert(0, str(root))\n",
    "logger.info(f\"Project root configured: {root}\")\n",
    "\n",
    "# Verify critical paths exist\n",
    "for path in [\"src\", \"data\", \"data/raw\", \"data/processed\", \"notebooks\"]:\n",
    "    if not (root / path).exists():\n",
    "        raise RuntimeError(f\"Missing required path: {root / path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd35c6",
   "metadata": {},
   "source": [
    "## Import Feature Engineering Functions\n",
    "\n",
    "Import the pre-implemented functions from our module. We'll try both potential import paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37855064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.features import (\n",
    "    height_to_inches, age_years, bmi,\n",
    "    angle_sin_cos_deg, angle_deg_to_rad, velocity_components, acceleration_components,\n",
    "    normalize_rightward, FIELD_LENGTH, FIELD_WIDTH,\n",
    "    add_formation_features, add_coverage_features, add_temporal_features,\n",
    ")\n",
    "\n",
    "# Define paths\n",
    "IN_PARQUET    = Path(\"data/parquet/test_input.parquet\")\n",
    "OUT_DIR       = Path(\"data/processed\")\n",
    "OUT_PLAYERS   = OUT_DIR / \"players_test.parquet\"\n",
    "OUT_TEAMFRAME = OUT_DIR / \"teamframe_test.parquet\"\n",
    "OUT_PLAYS     = OUT_DIR / \"plays_test.parquet\"\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe173846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory_usage() -> float:\n",
    "    \"\"\"Monitor memory usage and log if above threshold.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    memory_gb = process.memory_info().rss / 1024 / 1024 / 1024\n",
    "    if memory_gb > 8:  # Warning threshold at 8GB\n",
    "        logger.warning(f\"High memory usage: {memory_gb:.1f}GB\")\n",
    "        logger.info(\"Triggering garbage collection...\")\n",
    "        gc.collect()\n",
    "    return memory_gb\n",
    "\n",
    "def safe_load_parquet(path: Path) -> pl.DataFrame:\n",
    "    \"\"\"Safely load a parquet file with error handling.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Loading parquet file: {path}\")\n",
    "        df = pl.read_parquet(path)\n",
    "        logger.info(f\"Successfully loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading {path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_numeric_features(df: pl.DataFrame, numeric_cols: list[str]) -> None:\n",
    "    \"\"\"Validate numeric features for common issues.\"\"\"\n",
    "    for col in numeric_cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        stats = df.select([\n",
    "            pl.col(col).mean().alias(\"mean\"),\n",
    "            pl.col(col).std().alias(\"std\"),\n",
    "            pl.col(col).min().alias(\"min\"),\n",
    "            pl.col(col).max().alias(\"max\"),\n",
    "            pl.col(col).null_count().alias(\"nulls\")\n",
    "        ])\n",
    "        mean, std, minv, maxv, nnull = stats.row(0)\n",
    "\n",
    "        if nnull and nnull > 0:\n",
    "            logger.warning(f\"Column {col} has {nnull} null values\")\n",
    "\n",
    "        has_inf = df.select(pl.col(col).is_infinite().any().alias(\"_any\")).row(0)[0]\n",
    "        if has_inf:\n",
    "            logger.warning(f\"Column {col} contains infinite values\")\n",
    "\n",
    "        if std and std > 0:\n",
    "            if (minv is not None and minv < mean - 5*std) or (maxv is not None and maxv > mean + 5*std):\n",
    "                logger.warning(f\"Column {col} has values >5 std from mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778db3f",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define utility functions for data normalization and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "547e8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rightward_cols(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Mirror coordinates to rightward direction and wrap angles (using simple expressions).\n",
    "    Adds normalized columns: x_norm, y_norm, dir_norm, o_norm\n",
    "    \"\"\"\n",
    "    # Normalize x and y based on play_direction (offense always right)\n",
    "    x_norm = (\n",
    "        pl.when(pl.col(\"play_direction\").str.to_lowercase() == \"left\")\n",
    "          .then(pl.lit(FIELD_LENGTH) - pl.col(\"x\"))\n",
    "          .otherwise(pl.col(\"x\"))\n",
    "          .cast(pl.Float64)\n",
    "          .alias(\"x_norm\")\n",
    "    )\n",
    "\n",
    "    y_norm = (\n",
    "        pl.when(pl.col(\"play_direction\").str.to_lowercase() == \"left\")\n",
    "          .then(pl.lit(FIELD_WIDTH) - pl.col(\"y\"))\n",
    "          .otherwise(pl.col(\"y\"))\n",
    "          .cast(pl.Float64)\n",
    "          .alias(\"y_norm\")\n",
    "    )\n",
    "\n",
    "    # For angles, add 180 when direction is left and wrap via modulo 360\n",
    "    dir_norm = (\n",
    "        pl.when(pl.col(\"play_direction\").str.to_lowercase() == \"left\")\n",
    "          .then((pl.col(\"dir\") + 180.0) % 360.0)\n",
    "          .otherwise(pl.col(\"dir\"))\n",
    "          .alias(\"dir_norm\")\n",
    "    )\n",
    "\n",
    "    o_norm = (\n",
    "        pl.when(pl.col(\"play_direction\").str.to_lowercase() == \"left\")\n",
    "          .then((pl.col(\"o\") + 180.0) % 360.0)\n",
    "          .otherwise(pl.col(\"o\"))\n",
    "          .alias(\"o_norm\")\n",
    "    )\n",
    "\n",
    "    return df.with_columns([x_norm, y_norm, dir_norm, o_norm])\n",
    "\n",
    "\n",
    "def add_basic_player_scalars(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Add basic player features and derived components.\"\"\"\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"player_height\").map_elements(height_to_inches, return_dtype=pl.Float64).alias(\"height_in\"),\n",
    "        pl.col(\"player_birth_date\").map_elements(age_years, return_dtype=pl.Float64).alias(\"player_age\"),\n",
    "    ]).with_columns([\n",
    "        pl.struct([\"player_weight\", \"height_in\"]).map_elements(\n",
    "            lambda s: bmi(s[\"player_weight\"], s[\"height_in\"])\n",
    "        ).alias(\"player_bmi\"),\n",
    "    ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"dir_norm\").map_elements(angle_deg_to_rad).alias(\"dir_rad\"),\n",
    "        pl.col(\"o_norm\").map_elements(angle_deg_to_rad).alias(\"o_rad\"),\n",
    "    ]).with_columns([\n",
    "        pl.col(\"dir_rad\").sin().alias(\"dir_sin\"),\n",
    "        pl.col(\"dir_rad\").cos().alias(\"dir_cos\"),\n",
    "        pl.col(\"o_rad\").sin().alias(\"o_sin\"),\n",
    "        pl.col(\"o_rad\").cos().alias(\"o_cos\"),\n",
    "    ]).drop([\"dir_rad\",\"o_rad\"])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"s\") * pl.col(\"dir_cos\")).alias(\"vx\"),\n",
    "        (pl.col(\"s\") * pl.col(\"dir_sin\")).alias(\"vy\"),\n",
    "        (pl.col(\"a\") * pl.col(\"dir_cos\")).alias(\"ax\"),\n",
    "        (pl.col(\"a\") * pl.col(\"dir_sin\")).alias(\"ay\"),\n",
    "    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbe261",
   "metadata": {},
   "source": [
    "## Feature Table Generation\n",
    "\n",
    "Create functions to build our three main feature tables:\n",
    "1. Player features\n",
    "2. Team-frame features\n",
    "3. Play summary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "940681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_players_table(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Build per-player, per-frame feature table.\n",
    "    Keys: (game_id, play_id, frame_id, nfl_id)\n",
    "    \"\"\"\n",
    "    logger.info(\"Building player features table...\")\n",
    "    df = df.sort([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])  # temporal order per player\n",
    "    df = rightward_cols(df)\n",
    "    logger.info(\"✓ Normalized coordinates\")\n",
    "    df = add_basic_player_scalars(df)\n",
    "    logger.info(\"✓ Added basic player features\")\n",
    "\n",
    "    df = add_temporal_features(\n",
    "        df,\n",
    "        window_sizes=(3,5),\n",
    "        game=\"game_id\", play=\"play_id\", pid=\"nfl_id\", frame=\"frame_id\",\n",
    "        s=\"s\", a=\"a\", dirc=\"dir_norm\", x=\"x_norm\", y=\"y_norm\",\n",
    "    )\n",
    "    logger.info(\"✓ Added temporal features\")\n",
    "\n",
    "    numeric_cols = [\n",
    "        \"x_norm\", \"y_norm\", \"dir_norm\", \"o_norm\", \"s\", \"a\", \n",
    "        \"vx\", \"vy\", \"ax\", \"ay\", \"height_in\", \"player_weight\", \n",
    "        \"player_age\", \"player_bmi\",\n",
    "        \"speed_rolling_mean_3\",\"speed_rolling_std_3\",\"accel_rolling_mean_3\",\"accel_rolling_std_3\",\n",
    "        \"speed_rolling_mean_5\",\"speed_rolling_std_5\",\"accel_rolling_mean_5\",\"accel_rolling_std_5\",\n",
    "        \"angular_velocity\",\"delta_x\",\"delta_y\",\"cumulative_distance\",\n",
    "    ]\n",
    "    validate_numeric_features(df, numeric_cols)\n",
    "\n",
    "    cols = [\n",
    "        # keys\n",
    "        \"game_id\",\"play_id\",\"frame_id\",\"nfl_id\",\n",
    "        # context\n",
    "        \"player_side\",\"player_role\",\"player_position\",\"player_to_predict\",\n",
    "        # position/motion\n",
    "        \"x_norm\",\"y_norm\",\"dir_norm\",\"o_norm\",\"s\",\"a\",\"vx\",\"vy\",\"ax\",\"ay\",\n",
    "        # trig\n",
    "        \"dir_sin\",\"dir_cos\",\"o_sin\",\"o_cos\",\n",
    "        # physical\n",
    "        \"height_in\",\"player_weight\",\"player_age\",\"player_bmi\",\n",
    "        # other\n",
    "        \"absolute_yardline_number\",\"num_frames_output\",\"ball_land_x\",\"ball_land_y\",\n",
    "        # temporal\n",
    "        \"speed_rolling_mean_3\",\"speed_rolling_std_3\",\"accel_rolling_mean_3\",\"accel_rolling_std_3\",\n",
    "        \"speed_rolling_mean_5\",\"speed_rolling_std_5\",\"accel_rolling_mean_5\",\"accel_rolling_std_5\",\n",
    "        \"angular_velocity\",\"delta_x\",\"delta_y\",\"cumulative_distance\",\n",
    "    ]\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    result = df.select(cols)\n",
    "    logger.info(f\"✓ Player features table complete: {result.shape}\")\n",
    "    return result\n",
    "\n",
    "def build_teamframe_table(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Build per-team, per-frame feature table.\n",
    "    Keys: (game_id, play_id, frame_id, player_side)\n",
    "    \"\"\"\n",
    "    logger.info(\"Building team-frame features table...\")\n",
    "    df = df.sort([\"game_id\", \"play_id\", \"frame_id\", \"player_side\"])  # stable order\n",
    "    df = rightward_cols(df)\n",
    "    logger.info(\"✓ Normalized coordinates\")\n",
    "\n",
    "    df_fm = add_formation_features(\n",
    "        df,\n",
    "        game=\"game_id\", play=\"play_id\", frame=\"frame_id\", side=\"player_side\",\n",
    "        x=\"x_norm\", y=\"y_norm\",\n",
    "    )\n",
    "    logger.info(\"✓ Added formation features\")\n",
    "\n",
    "    df_cov = add_coverage_features(\n",
    "        df_fm,\n",
    "        radii=(3.0,5.0,7.0),\n",
    "        game=\"game_id\", play=\"play_id\", frame=\"frame_id\",\n",
    "        side=\"player_side\", pid=\"nfl_id\",\n",
    "        x=\"x_norm\", y=\"y_norm\",\n",
    "    )\n",
    "    logger.info(\"✓ Added coverage features\")\n",
    "\n",
    "    keys = [\"game_id\",\"play_id\",\"frame_id\",\"player_side\"]\n",
    "    result = (\n",
    "        df_cov.group_by(keys)\n",
    "             .agg([\n",
    "                 pl.col(\"formation_width\").first(),\n",
    "                 pl.col(\"formation_depth\").first(),\n",
    "                 pl.col(\"formation_x_mean\").first(),\n",
    "                 pl.col(\"formation_y_mean\").first(),\n",
    "                 pl.col(\"distance_to_formation_center\").mean().alias(\"team_spread_mean\"),\n",
    "                 pl.col(\"relative_formation_depth\").std().alias(\"depth_std\"),\n",
    "                 pl.col(\"relative_formation_width\").std().alias(\"width_std\"),\n",
    "                 pl.col(\"distance_to_nearest_teammate\").mean().alias(\"nn_teammate_mean\"),\n",
    "                 pl.col(\"distance_to_nearest_opponent\").mean().alias(\"nn_opponent_mean\"),\n",
    "                 pl.col(\"coverage_density\").mean().alias(\"coverage_density_mean\"),\n",
    "                 pl.col(\"opponents_within_3yds\").sum().alias(\"opp_within_3yds_sum\"),\n",
    "                 pl.col(\"opponents_within_5yds\").sum().alias(\"opp_within_5yds_sum\"),\n",
    "                 pl.col(\"opponents_within_7yds\").sum().alias(\"opp_within_7yds_sum\"),\n",
    "                 pl.col(\"teammates_within_3yds\").sum().alias(\"tm_within_3yds_sum\"),\n",
    "                 pl.col(\"teammates_within_5yds\").sum().alias(\"tm_within_5yds_sum\"),\n",
    "                 pl.col(\"teammates_within_7yds\").sum().alias(\"tm_within_7yds_sum\"),\n",
    "             ])\n",
    "    )\n",
    "\n",
    "    numeric_cols = [\n",
    "        \"formation_width\",\"formation_depth\",\"formation_x_mean\",\"formation_y_mean\",\n",
    "        \"team_spread_mean\",\"depth_std\",\"width_std\",\"nn_teammate_mean\",\n",
    "        \"nn_opponent_mean\",\"coverage_density_mean\",\n",
    "    ]\n",
    "    validate_numeric_features(result, numeric_cols)\n",
    "    logger.info(f\"✓ Team-frame features table complete: {result.shape}\")\n",
    "    return result\n",
    "\n",
    "def build_plays_table(players: pl.DataFrame, teamframe: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Build per-play summary feature table using last frame of each side.\n",
    "    Keys: (game_id, play_id)\n",
    "    \"\"\"\n",
    "    logger.info(\"Building play features table...\")\n",
    "    play_keys = [\"game_id\", \"play_id\"]\n",
    "\n",
    "    # last frames for teamframe\n",
    "    tf_last_key = (\n",
    "        teamframe.group_by(play_keys + [\"player_side\"]).agg(pl.col(\"frame_id\").max().alias(\"frame_id\"))\n",
    "    )\n",
    "    last_tf = teamframe.join(tf_last_key, on=play_keys + [\"player_side\", \"frame_id\"], how=\"inner\")\n",
    "\n",
    "    # last frames for players\n",
    "    pl_last_key = (\n",
    "        players.group_by(play_keys + [\"player_side\"]).agg(pl.col(\"frame_id\").max().alias(\"frame_id\"))\n",
    "    )\n",
    "    last_players = players.join(pl_last_key, on=play_keys + [\"player_side\", \"frame_id\"], how=\"inner\")\n",
    "\n",
    "    # side-specific player summaries\n",
    "    play_agg = (\n",
    "        last_players.group_by(play_keys + [\"player_side\"]) \n",
    "                    .agg([\n",
    "                        pl.col(\"s\").mean().alias(\"mean_speed_last\"),\n",
    "                        pl.col(\"a\").mean().alias(\"mean_accel_last\"),\n",
    "                        pl.col(\"x_norm\").mean().alias(\"mean_x_last\"),\n",
    "                        pl.col(\"y_norm\").mean().alias(\"mean_y_last\"),\n",
    "                    ])\n",
    "    )\n",
    "\n",
    "    play_pivot = play_agg.pivot(\n",
    "        values=[\"mean_speed_last\",\"mean_accel_last\",\"mean_x_last\",\"mean_y_last\"],\n",
    "        index=play_keys,\n",
    "        on=\"player_side\",\n",
    "        aggregate_function=\"first\",\n",
    "    )\n",
    "\n",
    "    fm_pivot = (\n",
    "        last_tf.select(play_keys + [\"player_side\",\"formation_width\",\"formation_depth\"]) \n",
    "               .pivot(\n",
    "                   values=[\"formation_width\",\"formation_depth\"],\n",
    "                   index=play_keys,\n",
    "                   on=\"player_side\",\n",
    "                   aggregate_function=\"first\",\n",
    "               )\n",
    "    )\n",
    "\n",
    "    result = play_pivot.join(fm_pivot, on=play_keys, how=\"outer\")\n",
    "    numeric_cols = [c for c in result.columns if c not in play_keys]\n",
    "    validate_numeric_features(result, numeric_cols)\n",
    "    logger.info(f\"✓ Play features table complete: {result.shape}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794963c",
   "metadata": {},
   "source": [
    "## Process and Save Feature Tables\n",
    "\n",
    "Load the input data and generate all feature tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "500a680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 18:09:25,447 - INFO - \n",
      "Processing test data...\n",
      "2025-11-01 18:09:25,449 - INFO - Loading test data from data\\parquet\\test_input.parquet\n",
      "2025-11-01 18:09:25,450 - INFO - Loading parquet file: data\\parquet\\test_input.parquet\n",
      "2025-11-01 18:09:25,449 - INFO - Loading test data from data\\parquet\\test_input.parquet\n",
      "2025-11-01 18:09:25,450 - INFO - Loading parquet file: data\\parquet\\test_input.parquet\n",
      "2025-11-01 18:09:25,472 - INFO - Successfully loaded 49753 rows and 24 columns\n",
      "2025-11-01 18:09:25,473 - INFO - Input test data: (49753, 24)\n",
      "2025-11-01 18:09:25,474 - INFO - \n",
      "Building feature tables...\n",
      "2025-11-01 18:09:25,475 - INFO - Building player features table...\n",
      "2025-11-01 18:09:25,472 - INFO - Successfully loaded 49753 rows and 24 columns\n",
      "2025-11-01 18:09:25,473 - INFO - Input test data: (49753, 24)\n",
      "2025-11-01 18:09:25,474 - INFO - \n",
      "Building feature tables...\n",
      "2025-11-01 18:09:25,475 - INFO - Building player features table...\n",
      "2025-11-01 18:09:25,509 - INFO - ✓ Normalized coordinates\n",
      "2025-11-01 18:09:25,509 - INFO - ✓ Normalized coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: df type: <class 'polars.dataframe.frame.DataFrame'>\n",
      "DEBUG: Polars DF shape: (49753, 24)\n",
      "DEBUG: columns: ['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight', 'player_birth_date', 'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a', 'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y', 'week']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 18:09:25,753 - INFO - ✓ Added basic player features\n",
      "2025-11-01 18:09:25,814 - INFO - ✓ Added temporal features\n",
      "2025-11-01 18:09:25,819 - WARNING - Column a has values >5 std from mean\n",
      "2025-11-01 18:09:25,824 - WARNING - Column ay has values >5 std from mean\n",
      "2025-11-01 18:09:25,814 - INFO - ✓ Added temporal features\n",
      "2025-11-01 18:09:25,819 - WARNING - Column a has values >5 std from mean\n",
      "2025-11-01 18:09:25,824 - WARNING - Column ay has values >5 std from mean\n",
      "2025-11-01 18:09:25,828 - WARNING - Column player_weight has values >5 std from mean\n",
      "2025-11-01 18:09:25,833 - WARNING - Column player_bmi has values >5 std from mean\n",
      "2025-11-01 18:09:25,834 - WARNING - Column speed_rolling_mean_3 has 3516 null values\n",
      "2025-11-01 18:09:25,836 - WARNING - Column speed_rolling_std_3 has 3516 null values\n",
      "2025-11-01 18:09:25,838 - WARNING - Column accel_rolling_mean_3 has 3516 null values\n",
      "2025-11-01 18:09:25,840 - WARNING - Column accel_rolling_std_3 has 3516 null values\n",
      "2025-11-01 18:09:25,828 - WARNING - Column player_weight has values >5 std from mean\n",
      "2025-11-01 18:09:25,833 - WARNING - Column player_bmi has values >5 std from mean\n",
      "2025-11-01 18:09:25,834 - WARNING - Column speed_rolling_mean_3 has 3516 null values\n",
      "2025-11-01 18:09:25,836 - WARNING - Column speed_rolling_std_3 has 3516 null values\n",
      "2025-11-01 18:09:25,838 - WARNING - Column accel_rolling_mean_3 has 3516 null values\n",
      "2025-11-01 18:09:25,840 - WARNING - Column accel_rolling_std_3 has 3516 null values\n",
      "2025-11-01 18:09:25,846 - WARNING - Column accel_rolling_std_3 has values >5 std from mean\n",
      "2025-11-01 18:09:25,849 - WARNING - Column speed_rolling_mean_5 has 7032 null values\n",
      "2025-11-01 18:09:25,846 - WARNING - Column accel_rolling_std_3 has values >5 std from mean\n",
      "2025-11-01 18:09:25,849 - WARNING - Column speed_rolling_mean_5 has 7032 null values\n",
      "2025-11-01 18:09:25,859 - WARNING - Column speed_rolling_std_5 has 7032 null values\n",
      "2025-11-01 18:09:25,875 - WARNING - Column accel_rolling_mean_5 has 7032 null values\n",
      "2025-11-01 18:09:25,859 - WARNING - Column speed_rolling_std_5 has 7032 null values\n",
      "2025-11-01 18:09:25,875 - WARNING - Column accel_rolling_mean_5 has 7032 null values\n",
      "2025-11-01 18:09:25,879 - WARNING - Column accel_rolling_std_5 has 7032 null values\n",
      "2025-11-01 18:09:25,881 - WARNING - Column accel_rolling_std_5 has values >5 std from mean\n",
      "2025-11-01 18:09:25,883 - WARNING - Column angular_velocity has 1758 null values\n",
      "2025-11-01 18:09:25,885 - WARNING - Column angular_velocity has values >5 std from mean\n",
      "2025-11-01 18:09:25,879 - WARNING - Column accel_rolling_std_5 has 7032 null values\n",
      "2025-11-01 18:09:25,881 - WARNING - Column accel_rolling_std_5 has values >5 std from mean\n",
      "2025-11-01 18:09:25,883 - WARNING - Column angular_velocity has 1758 null values\n",
      "2025-11-01 18:09:25,885 - WARNING - Column angular_velocity has values >5 std from mean\n",
      "2025-11-01 18:09:25,888 - WARNING - Column delta_x has 1758 null values\n",
      "2025-11-01 18:09:25,891 - WARNING - Column delta_y has 1758 null values\n",
      "2025-11-01 18:09:25,897 - WARNING - Column cumulative_distance has 1758 null values\n",
      "2025-11-01 18:09:25,888 - WARNING - Column delta_x has 1758 null values\n",
      "2025-11-01 18:09:25,891 - WARNING - Column delta_y has 1758 null values\n",
      "2025-11-01 18:09:25,897 - WARNING - Column cumulative_distance has 1758 null values\n",
      "2025-11-01 18:09:25,899 - WARNING - Column cumulative_distance has values >5 std from mean\n",
      "2025-11-01 18:09:25,901 - INFO - ✓ Player features table complete: (49753, 42)\n",
      "2025-11-01 18:09:25,903 - INFO - ✓ Player features: (49753, 42)\n",
      "2025-11-01 18:09:25,904 - INFO - Building team-frame features table...\n",
      "2025-11-01 18:09:25,941 - INFO - ✓ Normalized coordinates\n",
      "2025-11-01 18:09:25,899 - WARNING - Column cumulative_distance has values >5 std from mean\n",
      "2025-11-01 18:09:25,901 - INFO - ✓ Player features table complete: (49753, 42)\n",
      "2025-11-01 18:09:25,903 - INFO - ✓ Player features: (49753, 42)\n",
      "2025-11-01 18:09:25,904 - INFO - Building team-frame features table...\n",
      "2025-11-01 18:09:25,941 - INFO - ✓ Normalized coordinates\n",
      "2025-11-01 18:09:25,994 - INFO - ✓ Added formation features\n",
      "2025-11-01 18:09:25,994 - INFO - ✓ Added formation features\n",
      "2025-11-01 18:09:26,380 - INFO - ✓ Added coverage features\n",
      "2025-11-01 18:09:26,391 - WARNING - Column formation_depth has values >5 std from mean\n",
      "2025-11-01 18:09:26,380 - INFO - ✓ Added coverage features\n",
      "2025-11-01 18:09:26,391 - WARNING - Column formation_depth has values >5 std from mean\n",
      "2025-11-01 18:09:26,394 - WARNING - Column formation_y_mean has values >5 std from mean\n",
      "2025-11-01 18:09:26,400 - WARNING - Column nn_teammate_mean has values >5 std from mean\n",
      "2025-11-01 18:09:26,406 - INFO - ✓ Team-frame features table complete: (8070, 20)\n",
      "2025-11-01 18:09:26,407 - INFO - ✓ Team-frame features: (8070, 20)\n",
      "2025-11-01 18:09:26,394 - WARNING - Column formation_y_mean has values >5 std from mean\n",
      "2025-11-01 18:09:26,400 - WARNING - Column nn_teammate_mean has values >5 std from mean\n",
      "2025-11-01 18:09:26,406 - INFO - ✓ Team-frame features table complete: (8070, 20)\n",
      "2025-11-01 18:09:26,407 - INFO - ✓ Team-frame features: (8070, 20)\n",
      "2025-11-01 18:09:26,409 - INFO - Building play features table...\n",
      "2025-11-01 18:09:26,409 - INFO - Building play features table...\n",
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_8516\\2204444314.py:160: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n",
      "(Deprecated in version 0.20.29)\n",
      "  result = play_pivot.join(fm_pivot, on=play_keys, how=\"outer\")\n",
      "2025-11-01 18:09:26,583 - INFO - ✓ Play features table complete: (143, 16)\n",
      "2025-11-01 18:09:26,584 - INFO - ✓ Play features: (143, 16)\n",
      "2025-11-01 18:09:26,586 - INFO - \n",
      "Saving feature tables...\n",
      "C:\\Users\\Brandon\\AppData\\Local\\Temp\\ipykernel_8516\\2204444314.py:160: DeprecationWarning: use of `how='outer'` should be replaced with `how='full'`.\n",
      "(Deprecated in version 0.20.29)\n",
      "  result = play_pivot.join(fm_pivot, on=play_keys, how=\"outer\")\n",
      "2025-11-01 18:09:26,583 - INFO - ✓ Play features table complete: (143, 16)\n",
      "2025-11-01 18:09:26,584 - INFO - ✓ Play features: (143, 16)\n",
      "2025-11-01 18:09:26,586 - INFO - \n",
      "Saving feature tables...\n",
      "2025-11-01 18:09:27,243 - INFO - \n",
      "✓ Feature tables saved successfully:\n",
      "2025-11-01 18:09:27,244 - INFO -  - data\\processed\\players_test.parquet\n",
      "2025-11-01 18:09:27,247 - INFO -  - data\\processed\\teamframe_test.parquet\n",
      "2025-11-01 18:09:27,247 - INFO -  - data\\processed\\plays_test.parquet\n",
      "2025-11-01 18:09:27,249 - INFO - \n",
      "Cleaning up memory...\n",
      "2025-11-01 18:09:27,243 - INFO - \n",
      "✓ Feature tables saved successfully:\n",
      "2025-11-01 18:09:27,244 - INFO -  - data\\processed\\players_test.parquet\n",
      "2025-11-01 18:09:27,247 - INFO -  - data\\processed\\teamframe_test.parquet\n",
      "2025-11-01 18:09:27,247 - INFO -  - data\\processed\\plays_test.parquet\n",
      "2025-11-01 18:09:27,249 - INFO - \n",
      "Cleaning up memory...\n",
      "2025-11-01 18:09:27,354 - INFO - Final memory usage: 0.3GB\n",
      "2025-11-01 18:09:27,354 - INFO - Final memory usage: 0.3GB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"\\nProcessing test data...\")\n",
    "    logger.info(f\"Loading test data from {IN_PARQUET}\")\n",
    "    df = safe_load_parquet(IN_PARQUET)\n",
    "    initial_memory = check_memory_usage()\n",
    "    logger.info(f\"Input test data: {df.shape}\")\n",
    "\n",
    "    logger.info(\"\\nBuilding feature tables...\")\n",
    "\n",
    "    print(\"DEBUG: df type:\", type(df))\n",
    "    if isinstance(df, pl.DataFrame):\n",
    "        print(\"DEBUG: Polars DF shape:\", df.shape)\n",
    "        print(\"DEBUG: columns:\", df.columns)\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        print(\"DEBUG: Pandas DF shape:\", df.shape)\n",
    "        print(\"DEBUG: columns:\", list(df.columns))\n",
    "    else:\n",
    "        print(\"DEBUG: df is neither polars nor pandas; value:\", repr(df))\n",
    "\n",
    "\n",
    "    players = build_players_table(df)\n",
    "    logger.info(f\"✓ Player features: {players.shape}\")\n",
    "\n",
    "    teamframe = build_teamframe_table(df)\n",
    "    logger.info(f\"✓ Team-frame features: {teamframe.shape}\")\n",
    "\n",
    "    plays = build_plays_table(players, teamframe)\n",
    "    logger.info(f\"✓ Play features: {plays.shape}\")\n",
    "\n",
    "    logger.info(\"\\nSaving feature tables...\")\n",
    "    players.write_parquet(OUT_PLAYERS)\n",
    "    teamframe.write_parquet(OUT_TEAMFRAME)\n",
    "    plays.write_parquet(OUT_PLAYS)\n",
    "\n",
    "    logger.info(\"\\n✓ Feature tables saved successfully:\")\n",
    "    logger.info(f\" - {OUT_PLAYERS}\")\n",
    "    logger.info(f\" - {OUT_TEAMFRAME}\")\n",
    "    logger.info(f\" - {OUT_PLAYS}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during feature processing: {str(e)}\")\n",
    "    raise\n",
    "finally:\n",
    "    logger.info(\"\\nCleaning up memory...\")\n",
    "    for name in (\"df\",\"players\",\"teamframe\",\"plays\"):\n",
    "        if name in locals():\n",
    "            del locals()[name]\n",
    "    gc.collect()\n",
    "    final_memory = check_memory_usage()\n",
    "    logger.info(f\"Final memory usage: {final_memory:.1f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7468d9",
   "metadata": {},
   "source": [
    "## Feature Table Summary\n",
    "\n",
    "Let's examine the structure and content of our generated feature tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c003d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_feature_table(df: pl.DataFrame, name: str):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nColumns:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(df.head(3))\n",
    "\n",
    "# Uncomment to view summaries after running pipeline above\n",
    "# players = pl.read_parquet(OUT_PLAYERS)\n",
    "# teamframe = pl.read_parquet(OUT_TEAMFRAME)\n",
    "# plays = pl.read_parquet(OUT_PLAYS)\n",
    "# summarize_feature_table(players,  \"Player Features\")\n",
    "# summarize_feature_table(teamframe, \"Team-Frame Features\")\n",
    "# summarize_feature_table(plays,     \"Play Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6fcbe7",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2a3b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tables present and keys are unique\n"
     ]
    }
   ],
   "source": [
    "players_pq   = Path(\"data/processed/players_test.parquet\")\n",
    "teamframe_pq = Path(\"data/processed/teamframe_test.parquet\")\n",
    "plays_pq     = Path(\"data/processed/plays_test.parquet\")\n",
    "\n",
    "# 1) Files exist\n",
    "for p in [players_pq, teamframe_pq, plays_pq]:\n",
    "    assert p.exists(), f\"Missing: {p}\"\n",
    "\n",
    "players   = pl.read_parquet(players_pq)\n",
    "teamframe = pl.read_parquet(teamframe_pq)\n",
    "plays     = pl.read_parquet(plays_pq)\n",
    "\n",
    "def assert_pk_unique(df: pl.DataFrame, keys: list[str], name: str):\n",
    "    # Build a composite key string safely\n",
    "    key_exprs = [pl.col(k).cast(pl.Utf8) for k in keys]\n",
    "    k = pl.concat_str(key_exprs, separator=\"|\").alias(\"__pk__\")\n",
    "    dup_cnt = df.select(k).to_series().is_duplicated().sum()\n",
    "    if dup_cnt != 0:\n",
    "        # show a few duplicates for debugging\n",
    "        dups = (\n",
    "            df.with_columns(k)\n",
    "              .group_by(\"__pk__\")\n",
    "              .len()\n",
    "              .filter(pl.col(\"len\") > 1)\n",
    "              .head(10)\n",
    "        )\n",
    "        raise AssertionError(\n",
    "            f\"{name} primary key not unique on {keys}. Found {dup_cnt} duplicate rows.\\n\"\n",
    "            f\"Examples:\\n{dups}\"\n",
    "        )\n",
    "\n",
    "# 2) Primary key uniqueness\n",
    "assert_pk_unique(players,   [\"game_id\",\"play_id\",\"frame_id\",\"nfl_id\"],     \"players\")\n",
    "assert_pk_unique(teamframe, [\"game_id\",\"play_id\",\"frame_id\",\"player_side\"], \"teamframe\")\n",
    "assert_pk_unique(plays,     [\"game_id\",\"play_id\"],                          \"plays\")\n",
    "\n",
    "print(\"✅ tables present and keys are unique\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
